# ğŸ—ï¸ SYSTEM DESIGN ARCHITECTURE DIAGRAMS
## Visual References for Monday.com Interview

---

## 1ï¸âƒ£ ML RECOMMENDATION SYSTEM

### High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MONDAY.COM USERS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    API GATEWAY        â”‚
                    â”‚  - Authentication     â”‚
                    â”‚  - Rate Limiting      â”‚
                    â”‚  - Request Routing    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   LOAD BALANCER       â”‚
                    â”‚   (AWS ALB/NLB)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Model Server â”‚ â”‚Model Serverâ”‚ â”‚Model Serverâ”‚
        â”‚   Pod 1      â”‚ â”‚   Pod 2    â”‚ â”‚   Pod 3    â”‚
        â”‚ (Kubernetes) â”‚ â”‚(Kubernetes)â”‚ â”‚(Kubernetes)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚               â”‚               â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     FEATURE STORE              â”‚
                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                â”‚  â”‚  Redis Cache (Hot)       â”‚  â”‚
                â”‚  â”‚  - Last 1hr features     â”‚  â”‚
                â”‚  â”‚  - User behavior         â”‚  â”‚
                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                â”‚  â”‚  DynamoDB (Warm)         â”‚  â”‚
                â”‚  â”‚  - Last 30d features     â”‚  â”‚
                â”‚  â”‚  - Board usage patterns  â”‚  â”‚
                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Model        â”‚ â”‚ A/B Testingâ”‚ â”‚ Monitoring â”‚
        â”‚ Registry     â”‚ â”‚ Framework  â”‚ â”‚ & Alerts   â”‚
        â”‚              â”‚ â”‚            â”‚ â”‚            â”‚
        â”‚ - MLflow     â”‚ â”‚ - Variant Aâ”‚ â”‚ - Grafana  â”‚
        â”‚ - Versions   â”‚ â”‚ - Variant Bâ”‚ â”‚ - Prometheusâ”‚
        â”‚ - Metadata   â”‚ â”‚ - Traffic  â”‚ â”‚ - Drift    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    FEEDBACK LOOP              â”‚
                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                â”‚  â”‚ User Actions (Kafka)    â”‚  â”‚
                â”‚  â”‚ - Clicks, Ignores       â”‚  â”‚
                â”‚  â”‚ - Time spent            â”‚  â”‚
                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                â”‚            â”‚                   â”‚
                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                â”‚  â”‚ Retraining Pipeline     â”‚  â”‚
                â”‚  â”‚ - Spark/Airflow         â”‚  â”‚
                â”‚  â”‚ - Weekly schedule       â”‚  â”‚
                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Sequence
```
User Request:
1. User opens Monday.com dashboard
2. API Gateway authenticates & routes to Recommendation Service
3. Service fetches features from Redis (if cache hit) or DynamoDB
4. Model Server loads model from Registry (if not in memory)
5. Model generates top 10 recommendations
6. Results returned to user (<100ms p95 latency)
7. User interaction logged to Kafka
8. Feedback used for model retraining

Multi-Tenant Isolation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Request Headers:                      â”‚
â”‚  - customer_id: "acme_corp"            â”‚
â”‚  - user_id: "user_123"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Store Partitioning:           â”‚
â”‚  Key: "customer_id:user_id:feature"    â”‚
â”‚  Example: "acme_corp:user_123:clicks"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Predictions:                    â”‚
â”‚  - Isolated by customer_id             â”‚
â”‚  - No cross-customer leakage           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scaling Strategy
```
Traffic Pattern:
09:00 AM â”€â”€â–¶ Peak (10K req/sec)
             â”œâ”€ HPA scales pods: 3 â†’ 10
             â”œâ”€ Redis cache hit rate: 95%
             â””â”€ Latency: p95 < 100ms

02:00 PM â”€â”€â–¶ Normal (3K req/sec)
             â”œâ”€ HPA maintains: 5 pods
             â””â”€ Latency: p95 < 50ms

11:00 PM â”€â”€â–¶ Low (500 req/sec)
             â”œâ”€ HPA scales down: 3 pods
             â””â”€ Cost optimization
```

---

## 2ï¸âƒ£ REAL-TIME ANALYTICS DASHBOARD

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVENT SOURCES                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Board    â”‚ â”‚ User     â”‚ â”‚ Auto-    â”‚ â”‚ Integra- â”‚          â”‚
â”‚  â”‚ Activity â”‚ â”‚ Actions  â”‚ â”‚ mations  â”‚ â”‚ tions    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   EVENT INGESTION     â”‚
                    â”‚   (Kafka / Kinesis)   â”‚
                    â”‚                       â”‚
                    â”‚ - 100K events/sec     â”‚
                    â”‚ - Partitioned by      â”‚
                    â”‚   customer_id         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Stream       â”‚ â”‚ Batch      â”‚ â”‚ Backup     â”‚
        â”‚ Processing   â”‚ â”‚ Processing â”‚ â”‚ Storage    â”‚
        â”‚              â”‚ â”‚            â”‚ â”‚            â”‚
        â”‚ - Flink/     â”‚ â”‚ - Spark    â”‚ â”‚ - S3       â”‚
        â”‚   Spark      â”‚ â”‚ - Hourly   â”‚ â”‚ - Parquet  â”‚
        â”‚   Streaming  â”‚ â”‚   aggr.    â”‚ â”‚ - 90 days  â”‚
        â”‚ - Real-time  â”‚ â”‚ - Complex  â”‚ â”‚ - Audit    â”‚
        â”‚   metrics    â”‚ â”‚   queries  â”‚ â”‚   trail    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚               â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                        â”‚ Time-Series  â”‚ â”‚ Cache      â”‚
                        â”‚ Database     â”‚ â”‚ (Redis)    â”‚
                        â”‚              â”‚ â”‚            â”‚
                        â”‚ - InfluxDB/  â”‚ â”‚ - Last 1hr â”‚
                        â”‚   TimescaleDBâ”‚ â”‚ - Pre-aggr â”‚
                        â”‚ - Downsampledâ”‚ â”‚ - Dashboardâ”‚
                        â”‚   1min â†’ 1hr â”‚ â”‚   queries  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                â”‚               â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                â”‚ API Layer    â”‚
                                â”‚              â”‚
                                â”‚ - REST API   â”‚
                                â”‚ - GraphQL    â”‚
                                â”‚ - WebSocket  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                â”‚ Dashboard    â”‚
                                â”‚ (React)      â”‚
                                â”‚              â”‚
                                â”‚ - Real-time  â”‚
                                â”‚   updates    â”‚
                                â”‚ - Charts     â”‚
                                â”‚ - Filters    â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Pipeline
```
Event Journey:
1. User clicks button â†’ Event generated
   {
     "event_type": "button_click",
     "customer_id": "acme_corp",
     "user_id": "user_123",
     "timestamp": 1703250000,
     "metadata": {...}
   }

2. Kafka Topic: "user_events"
   - Partition: hash(customer_id) % num_partitions
   - Replication factor: 3
   - Retention: 7 days

3. Stream Processing (Flink):
   - Tumbling window: 1 minute
   - Aggregate: count, sum, avg
   - Output: metrics per customer

4. Write to InfluxDB:
   measurement: user_activity
   tags: customer_id, event_type
   fields: count, avg_duration
   time: timestamp

5. Cache in Redis:
   Key: "dashboard:{customer_id}:last_hour"
   Value: JSON with pre-aggregated metrics
   TTL: 3600 seconds

6. WebSocket Push:
   Server â†’ Client: New data available
   Client pulls from API
   Dashboard updates chart
```

### Query Optimization
```
Common Query: "Show board activity for last 24 hours"

Without Optimization:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scan InfluxDB: 24 hours Ã— all events  â”‚
â”‚ Time: 5-10 seconds âŒ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Optimization:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check Redis cache (last 1 hour)    â”‚
â”‚    - Hit: Return immediately (10ms)    â”‚
â”‚                                        â”‚
â”‚ 2. Query InfluxDB (hours 2-24)        â”‚
â”‚    - Use downsampled data (1min avg)  â”‚
â”‚    - Time: 200ms                       â”‚
â”‚                                        â”‚
â”‚ 3. Merge results                       â”‚
â”‚    - Total: 210ms âœ…                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3ï¸âƒ£ NOTIFICATION SYSTEM

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NOTIFICATION TRIGGERS                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ @Mention â”‚ â”‚ Deadline â”‚ â”‚ Status   â”‚ â”‚ Automationâ”‚          â”‚
â”‚  â”‚          â”‚ â”‚ Reminder â”‚ â”‚ Change   â”‚ â”‚ Complete  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  NOTIFICATION API     â”‚
                    â”‚                       â”‚
                    â”‚ - Validate request    â”‚
                    â”‚ - Check user prefs    â”‚
                    â”‚ - Determine channels  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PRIORITY ROUTER     â”‚
                    â”‚                       â”‚
                    â”‚ HIGH    â”‚ MEDIUM â”‚ LOWâ”‚
                    â”‚ (Urgent)â”‚(Normal)â”‚(Bulk)â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”¬â”˜
                          â”‚        â”‚       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”
              â”‚ High Priority â”‚ â”‚Mediumâ”‚ â”‚ Low â”‚
              â”‚ Queue (SQS)   â”‚ â”‚Queue â”‚ â”‚Queueâ”‚
              â”‚               â”‚ â”‚      â”‚ â”‚     â”‚
              â”‚ - @mentions   â”‚ â”‚ -Upd â”‚ â”‚-Newsâ”‚
              â”‚ - Critical    â”‚ â”‚ ates â”‚ â”‚-Tipsâ”‚
              â”‚   alerts      â”‚ â”‚      â”‚ â”‚     â”‚
              â”‚ DLQ: 3 retriesâ”‚ â”‚3 retrâ”‚ â”‚1 retâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”¬â”€â”€â”€â”˜
                      â”‚            â”‚       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚           â”‚            â”‚       â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Worker    â”‚ â”‚Work â”‚ â”‚ Worker â”‚ â”‚Workerâ”‚ â”‚ Worker    â”‚
    â”‚ Pool 1    â”‚ â”‚ er 2â”‚ â”‚ Pool 3 â”‚ â”‚Pool 4â”‚ â”‚ Pool 5    â”‚
    â”‚           â”‚ â”‚     â”‚ â”‚        â”‚ â”‚      â”‚ â”‚ (Batch)   â”‚
    â”‚ - Process â”‚ â”‚-Pro â”‚ â”‚-Processâ”‚ â”‚-Proc â”‚ â”‚ - Email   â”‚
    â”‚ - Rate    â”‚ â”‚cess â”‚ â”‚ - Rate â”‚ â”‚ ess  â”‚ â”‚   digest  â”‚
    â”‚   limit   â”‚ â”‚-Rateâ”‚ â”‚   limitâ”‚ â”‚-Rate â”‚ â”‚ - Once/dayâ”‚
    â”‚ - Deliver â”‚ â”‚ lim â”‚ â”‚ - Delvrâ”‚ â”‚ lim  â”‚ â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚          â”‚         â”‚         â”‚          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                   â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ PUSH         â”‚  â”‚ EMAIL             â”‚  â”‚ WEBHOOKS    â”‚
    â”‚ (Firebase)   â”‚  â”‚ (SendGrid/SES)    â”‚  â”‚             â”‚
    â”‚              â”‚  â”‚                   â”‚  â”‚ - Slack     â”‚
    â”‚ - Mobile app â”‚  â”‚ - Templates       â”‚  â”‚ - Teams     â”‚
    â”‚ - Real-time  â”‚  â”‚ - Unsubscribe     â”‚  â”‚ - Custom    â”‚
    â”‚ - 99% deliv  â”‚  â”‚ - Tracking        â”‚  â”‚ - Retries   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DELIVERY TRACKER     â”‚
                    â”‚  (DynamoDB)           â”‚
                    â”‚                       â”‚
                    â”‚ - Status: sent/failed â”‚
                    â”‚ - Retry count         â”‚
                    â”‚ - Delivery time       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rate Limiting Strategy
```
Per-User Rate Limits:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Channel     â”‚ Limit        â”‚ Window   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Push        â”‚ 10 notifs    â”‚ 1 hour   â”‚
â”‚ Email       â”‚ 5 emails     â”‚ 1 hour   â”‚
â”‚ In-app      â”‚ Unlimited    â”‚ -        â”‚
â”‚ Slack       â”‚ 20 messages  â”‚ 1 hour   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Implementation (Redis):
Key: "rate_limit:{user_id}:{channel}"
Value: Counter
Expire: 3600 seconds

if redis.incr(key) > limit:
    # Queue for later or drop
    return "Rate limited"
else:
    # Send notification
    send_notification()
```

### Failure Handling
```
Notification Lifecycle:

Created â†’ Queued â†’ Processing â†’ Delivered
   â†“         â†“          â†“            â†“
Failed    Failed    Failed      Confirmed
   â†“         â†“          â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚ Retry Logic â”‚
      â”‚             â”‚
      â”‚ Attempt 1:  â”‚ Immediate
      â”‚ Attempt 2:  â”‚ +5 minutes
      â”‚ Attempt 3:  â”‚ +30 minutes
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚ Dead Letter â”‚
      â”‚ Queue       â”‚
      â”‚             â”‚
      â”‚ - Alert ops â”‚
      â”‚ - Manual    â”‚
      â”‚   review    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4ï¸âƒ£ SEARCH & AUTOCOMPLETE SERVICE

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INPUT                                â”‚
â”‚                    "meeting with..."                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  SEARCH API           â”‚
                 â”‚                       â”‚
                 â”‚ - Parse query         â”‚
                 â”‚ - Apply filters       â”‚
                 â”‚ - Add context         â”‚
                 â”‚   (customer_id,       â”‚
                 â”‚    user permissions)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  CACHE LAYER          â”‚
                 â”‚  (Redis)              â”‚
                 â”‚                       â”‚
                 â”‚ - Recent searches     â”‚
                 â”‚ - Popular queries     â”‚
                 â”‚ - Personalized        â”‚
                 â”‚   results             â”‚
                 â”‚                       â”‚
                 â”‚ Cache Hit? â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                 â”‚   YES: Return      â”‚  â”‚
                 â”‚   NO: Continue     â”‚  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                             â”‚           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                 â”‚ ELASTICSEARCH        â”‚â”‚
                 â”‚ CLUSTER              â”‚â”‚
                 â”‚                      â”‚â”‚
                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
                 â”‚ â”‚ Index: boards    â”‚ â”‚â”‚
                 â”‚ â”‚ - name, desc     â”‚ â”‚â”‚
                 â”‚ â”‚ - items, columns â”‚ â”‚â”‚
                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
                 â”‚                      â”‚â”‚
                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
                 â”‚ â”‚ Index: items     â”‚ â”‚â”‚
                 â”‚ â”‚ - title, status  â”‚ â”‚â”‚
                 â”‚ â”‚ - updates, files â”‚ â”‚â”‚
                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
                 â”‚                      â”‚â”‚
                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
                 â”‚ â”‚ Index: people    â”‚ â”‚â”‚
                 â”‚ â”‚ - name, email    â”‚ â”‚â”‚
                 â”‚ â”‚ - team, role     â”‚ â”‚â”‚
                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
                 â”‚                      â”‚â”‚
                 â”‚ Sharding:            â”‚â”‚
                 â”‚ - Shard by           â”‚â”‚
                 â”‚   customer_id        â”‚â”‚
                 â”‚ - 5 shards/index     â”‚â”‚
                 â”‚ - 2 replicas         â”‚â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                             â”‚           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”
                 â”‚  RANKING ENGINE        â”‚
                 â”‚                        â”‚
                 â”‚ Score calculation:     â”‚
                 â”‚ - Text relevance (BM25)â”‚
                 â”‚ - Recency boost        â”‚
                 â”‚ - User history         â”‚
                 â”‚ - Popularity           â”‚
                 â”‚                        â”‚
                 â”‚ Final score =          â”‚
                 â”‚   0.6 Ã— relevance +    â”‚
                 â”‚   0.2 Ã— recency +      â”‚
                 â”‚   0.1 Ã— personal +     â”‚
                 â”‚   0.1 Ã— popular        â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  RESULTS               â”‚
                 â”‚                        â”‚
                 â”‚ Top 10 results         â”‚
                 â”‚ - Highlighted matches  â”‚
                 â”‚ - Facets (filters)     â”‚
                 â”‚ - Did you mean?        â”‚
                 â”‚ - Related searches     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Autocomplete Flow
```
User types: "m" â†’ "me" â†’ "mee" â†’ "meet"

Each keystroke triggers:

1. Client-side debounce (300ms)
   - Avoid overwhelming server
   - Wait for user to stop typing

2. API Request
   GET /autocomplete?q=meet&limit=5

3. Prefix Tree (Trie) Lookup
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚         ROOT                â”‚
   â”‚          /|\                â”‚
   â”‚         m ...               â”‚
   â”‚         |                   â”‚
   â”‚         e                   â”‚
   â”‚         |                   â”‚
   â”‚         e                   â”‚
   â”‚         |                   â”‚
   â”‚         t  â†â”€â”€ Current node â”‚
   â”‚        /|\                  â”‚
   â”‚       i n ing               â”‚
   â”‚       | |   |               â”‚
   â”‚       n g   [freq: 1000]    â”‚
   â”‚       | |                   â”‚
   â”‚  [freq] [freq]              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. Top Suggestions (by frequency)
   - "meeting" (1000 searches)
   - "meetings" (500 searches)
   - "meet deadline" (300)
   - "meeting room" (250)
   - "meet the team" (100)

5. Personalization Layer
   Add user's recent searches:
   - "meeting with Sarah" (user searched 2h ago)
   
   Boost to top of results

6. Return to client (<50ms)
```

### Index Update Pipeline
```
Data Change Flow:

Board/Item Updated
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Change Event     â”‚
â”‚ (Kafka)          â”‚
â”‚                  â”‚
â”‚ - action: UPDATE â”‚
â”‚ - entity: board  â”‚
â”‚ - customer_id    â”‚
â”‚ - data: {...}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Index Worker     â”‚
â”‚ (Consumer)       â”‚
â”‚                  â”‚
â”‚ - Transform data â”‚
â”‚ - Enrich with    â”‚
â”‚   metadata       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Elasticsearch    â”‚
â”‚ Bulk API         â”‚
â”‚                  â”‚
â”‚ - Batch 100 docs â”‚
â”‚ - Update index   â”‚
â”‚ - Refresh        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Delay: 1-2 seconds (eventual consistency)

For critical updates (e.g., permissions):
- Sync update
- Invalidate cache
- Immediate consistency
```

---

## 5ï¸âƒ£ FILE STORAGE & PROCESSING

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FILE UPLOAD                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  UPLOAD API           â”‚
                 â”‚                       â”‚
                 â”‚ 1. Validate file      â”‚
                 â”‚    - Size < 500MB     â”‚
                 â”‚    - Type allowed     â”‚
                 â”‚    - Virus scan       â”‚
                 â”‚                       â”‚
                 â”‚ 2. Generate           â”‚
                 â”‚    pre-signed URL     â”‚
                 â”‚                       â”‚
                 â”‚ 3. Return URL to      â”‚
                 â”‚    client             â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  CLIENT               â”‚
                 â”‚                       â”‚
                 â”‚ Direct upload to S3   â”‚
                 â”‚ (bypass API server)   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           S3 BUCKET                   â”‚
         â”‚   (Customer: acme_corp)               â”‚
         â”‚                                       â”‚
         â”‚   /uploads/                           â”‚
         â”‚     2024-12-22/                       â”‚
         â”‚       user_123/                       â”‚
         â”‚         abc123.jpg                    â”‚
         â”‚                                       â”‚
         â”‚   Lifecycle:                          â”‚
         â”‚   - Standard: 30 days                 â”‚
         â”‚   - IA: 30-90 days                    â”‚
         â”‚   - Glacier: 90+ days                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ (S3 Event)
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      EVENT PROCESSOR                  â”‚
         â”‚      (Lambda / SQS Worker)            â”‚
         â”‚                                       â”‚
         â”‚ 1. Virus scan (ClamAV)                â”‚
         â”‚    - Quarantine if infected           â”‚
         â”‚                                       â”‚
         â”‚ 2. Extract metadata                   â”‚
         â”‚    - File type, size, dimensions      â”‚
         â”‚    - EXIF data (images)               â”‚
         â”‚                                       â”‚
         â”‚ 3. Deduplication                      â”‚
         â”‚    - Calculate SHA-256 hash           â”‚
         â”‚    - Check if exists                  â”‚
         â”‚    - Link instead of duplicate        â”‚
         â”‚                                       â”‚
         â”‚ 4. Trigger processing pipeline        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚ IMAGE   â”‚  â”‚ VIDEO  â”‚  â”‚ DOCUMENT    â”‚    â”‚
    â”‚ PROCESS â”‚  â”‚ PROCESSâ”‚  â”‚ PROCESS     â”‚    â”‚
    â”‚         â”‚  â”‚        â”‚  â”‚             â”‚    â”‚
    â”‚ Tasks:  â”‚  â”‚ Tasks: â”‚  â”‚ Tasks:      â”‚    â”‚
    â”‚ - Thumb â”‚  â”‚ - Tran â”‚  â”‚ - OCR       â”‚    â”‚
    â”‚   nail  â”‚  â”‚   scodeâ”‚  â”‚ - Text      â”‚    â”‚
    â”‚   (3 sz)â”‚  â”‚ - 480p â”‚  â”‚   extract   â”‚    â”‚
    â”‚ - Resizeâ”‚  â”‚   720p â”‚  â”‚ - Preview   â”‚    â”‚
    â”‚ - Optim â”‚  â”‚   1080pâ”‚  â”‚   (PDF)     â”‚    â”‚
    â”‚   ize   â”‚  â”‚ - Thumbâ”‚  â”‚ - Index     â”‚    â”‚
    â”‚ - WebP  â”‚  â”‚   nail â”‚  â”‚   (search)  â”‚    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
         â”‚            â”‚             â”‚            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                      â”‚                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚   PROCESSED STORAGE   â”‚              â”‚
          â”‚   (S3)                â”‚              â”‚
          â”‚                       â”‚              â”‚
          â”‚   /processed/         â”‚              â”‚
          â”‚     abc123/           â”‚              â”‚
          â”‚       original.jpg    â”‚              â”‚
          â”‚       thumb_sm.jpg    â”‚              â”‚
          â”‚       thumb_md.jpg    â”‚              â”‚
          â”‚       thumb_lg.jpg    â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                      â”‚                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚   METADATA DB         â”‚              â”‚
          â”‚   (DynamoDB)          â”‚              â”‚
          â”‚                       â”‚              â”‚
          â”‚ {                     â”‚              â”‚
          â”‚   file_id: "abc123",  â”‚              â”‚
          â”‚   customer_id: "...", â”‚              â”‚
          â”‚   original_name: "...",â”‚              â”‚
          â”‚   size: 1024000,      â”‚              â”‚
          â”‚   type: "image/jpeg", â”‚              â”‚
          â”‚   hash: "sha256...",  â”‚              â”‚
          â”‚   urls: {             â”‚              â”‚
          â”‚     original: "...",  â”‚              â”‚
          â”‚     thumbnails: [...]  â”‚              â”‚
          â”‚   },                  â”‚              â”‚
          â”‚   processed: true,    â”‚              â”‚
          â”‚   created_at: "..."   â”‚              â”‚
          â”‚ }                     â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                      â”‚                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚   CDN                 â”‚              â”‚
          â”‚   (CloudFront)        â”‚              â”‚
          â”‚                       â”‚              â”‚
          â”‚ - Cache processed     â”‚              â”‚
          â”‚   files (24h TTL)     â”‚              â”‚
          â”‚ - Edge locations      â”‚              â”‚
          â”‚ - Signed URLs         â”‚              â”‚
          â”‚   (private files)     â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                      â”‚                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚   END USER            â”‚              â”‚
          â”‚                       â”‚              â”‚
          â”‚ - Fast delivery       â”‚              â”‚
          â”‚ - Appropriate size    â”‚              â”‚
          â”‚ - Secure access       â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
```

### Processing Pipeline Details
```
Image Processing (ImageMagick):

Original: 4000Ã—3000 px, 5MB
     â”‚
     â”œâ”€ Thumbnail Small:  150Ã—150 px, 20KB
     â”‚  - For list views
     â”‚  - WebP format
     â”‚  - Quality: 80%
     â”‚
     â”œâ”€ Thumbnail Medium: 500Ã—375 px, 80KB
     â”‚  - For previews
     â”‚  - WebP format
     â”‚  - Quality: 85%
     â”‚
     â”œâ”€ Thumbnail Large:  1200Ã—900 px, 300KB
     â”‚  - For lightbox
     â”‚  - WebP format
     â”‚  - Quality: 90%
     â”‚
     â””â”€ Optimized Original: 4000Ã—3000 px, 2MB
        - Compressed JPEG
        - Strip EXIF (privacy)
        - Quality: 85%

Video Processing (FFmpeg):

Original: 1920Ã—1080, 100MB, 2min
     â”‚
     â”œâ”€ 480p:  854Ã—480, 15MB
     â”‚  - Mobile viewing
     â”‚  - H.264 codec
     â”‚
     â”œâ”€ 720p:  1280Ã—720, 30MB
     â”‚  - Standard viewing
     â”‚  - H.264 codec
     â”‚
     â”œâ”€ 1080p: 1920Ã—1080, 50MB
     â”‚  - HD viewing
     â”‚  - H.264 codec
     â”‚
     â”œâ”€ Thumbnail: 1920Ã—1080, 200KB
     â”‚  - Frame at 00:01
     â”‚  - JPEG format
     â”‚
     â””â”€ HLS Playlist
        - Adaptive bitrate streaming
        - Multiple quality levels

Document Processing:

PDF (10 pages):
     â”‚
     â”œâ”€ Text Extraction (Apache Tika)
     â”‚  - Full text for search indexing
     â”‚  - Preserve formatting
     â”‚
     â”œâ”€ Preview Images
     â”‚  - First 3 pages as images
     â”‚  - 800Ã—1100 px
     â”‚
     â””â”€ Metadata
        - Author, creation date
        - Page count
        - File size
```

### Deduplication Logic
```
File Upload Flow:

1. Calculate Hash
   hash = SHA256(file_content)
   
2. Check Database
   SELECT * FROM files 
   WHERE customer_id = ? 
   AND hash = ?
   
3. If Exists:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Don't upload again!        â”‚
   â”‚                            â”‚
   â”‚ Instead:                   â”‚
   â”‚ - Create new file record   â”‚
   â”‚ - Point to existing S3 key â”‚
   â”‚ - Update reference count   â”‚
   â”‚                            â”‚
   â”‚ Savings:                   â”‚
   â”‚ - Storage: 100%            â”‚
   â”‚ - Processing: 100%         â”‚
   â”‚ - Upload time: 100%        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
4. If Not Exists:
   - Upload to S3
   - Process file
   - Store metadata
   - Set reference count = 1

Benefits:
- Same company logo uploaded 1000 times
- Actually stored only once
- 99.9% storage reduction
```

---

## ğŸ¯ KEY PATTERNS ACROSS ALL DESIGNS

### Multi-Tenancy Pattern
```
Every request includes:
- customer_id (company identifier)
- user_id (user identifier)

Data isolation:
1. Database level
   - Partition key: customer_id
   - No cross-customer queries

2. Cache level
   - Key prefix: customer_id:*
   - Separate cache namespaces

3. Storage level
   - S3 bucket structure: /customer_id/
   - No shared objects

4. Processing level
   - Queue partitioning by customer_id
   - Isolated worker pools for large customers
```

### Scaling Pattern
```
Horizontal Scaling (preferred):
- Add more pods/instances
- Load balance across them
- Stateless services

Vertical Scaling (limited):
- Increase CPU/memory
- Database only
- Has limits

Auto-scaling Triggers:
- CPU > 70% â†’ scale up
- CPU < 30% â†’ scale down
- Queue depth > 1000 â†’ scale up
- Latency p95 > target â†’ scale up
```

### Monitoring Pattern
```
Golden Signals (SRE):

1. Latency
   - p50, p95, p99
   - Target: p95 < 100ms

2. Traffic
   - Requests/second
   - Bytes in/out

3. Errors
   - Error rate (%)
   - Target: < 0.1%

4. Saturation
   - CPU, memory, disk
   - Queue depth

Alerts:
- Critical: Page ops immediately
- Warning: Ticket for review
- Info: Log only
```

### Failure Handling Pattern
```
Circuit Breaker:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ State: CLOSED (normal)         â”‚
â”‚ â†’ Error rate < 50%             â”‚
â”‚ â†’ Allow all requests           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (too many errors)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ State: OPEN (failing)          â”‚
â”‚ â†’ Reject all requests          â”‚
â”‚ â†’ Return cached/default        â”‚
â”‚ â†’ Wait 30 seconds              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (timeout)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ State: HALF-OPEN (testing)     â”‚
â”‚ â†’ Allow 10% of requests        â”‚
â”‚ â†’ If success â†’ CLOSED          â”‚
â”‚ â†’ If failure â†’ OPEN            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Retry Strategy:
- Retry 1: Immediate
- Retry 2: +1 second (exponential backoff)
- Retry 3: +2 seconds
- Give up: +4 seconds
- Total timeout: 7 seconds
```

---

## ğŸ§® CAPACITY ESTIMATION & CALCULATIONS

### Back-of-Envelope Math (Practice This!)
```
Powers of 2:
2^10 = 1K    (~1 thousand)
2^20 = 1M    (~1 million)
2^30 = 1B    (~1 billion)

Time:
1 day = 86,400 seconds  (~100K seconds)
1 month = 2.5M seconds
1 year = 31.5M seconds  (~30M seconds)

Storage:
1 KB = 1,000 bytes
1 MB = 1,000 KB
1 GB = 1,000 MB
1 TB = 1,000 GB
1 PB = 1,000 TB
```

### Example Calculation: Analytics System
```
Given:
- 150K customers
- Average 100 users per customer
- Each user generates 50 events/day

Calculate:
1. Events per second:
   150K customers Ã— 100 users Ã— 50 events/day
   = 750M events/day
   = 750M / 100K seconds
   = 7,500 events/sec average
   = ~25K events/sec peak (3x factor)

2. Storage per day:
   750M events Ã— 1KB per event
   = 750 GB/day
   = 22.5 TB/month
   = 270 TB/year (before compression)
   
3. With compression (5x):
   = 54 TB/year
   
4. With replication (3x):
   = 162 TB/year total storage

5. Bandwidth:
   25K events/sec Ã— 1KB
   = 25 MB/sec
   = 200 Mbps
```

### Example Calculation: File Storage
```
Given:
- 10M files uploaded per month
- Average file size: 2MB
- Need 3 thumbnail sizes per image

Calculate:
1. Storage per month:
   Original: 10M Ã— 2MB = 20 TB
   Thumbnails: 10M Ã— (20KB + 80KB + 300KB) = 4 TB
   Total: 24 TB/month
   
2. Processing time:
   - Assume 2 seconds per file processing
   - 10M files/month = 10M / 2.5M seconds
   - = 4 files/sec average
   - Need: 4 Ã— 2 = 8 worker cores minimum
   - With 3x buffer: 24 cores for workers

3. CDN bandwidth:
   - Assume each file viewed 10 times
   - 10M files Ã— 10 views Ã— 2MB = 200 TB/month
   - = ~60 Mbps average bandwidth
```

### Database Sharding Calculation
```
Given:
- Single DB can handle 10K queries/sec
- Need to support 100K queries/sec
- 99.9% uptime required

Calculate:
1. Number of shards:
   100K / 10K = 10 shards minimum
   
2. With redundancy (2 replicas each):
   10 shards Ã— 3 (1 primary + 2 replicas) = 30 DB instances
   
3. With one shard down:
   - 9 shards handle 90K queries/sec
   - Each shard now at 10K queries/sec (still ok)
   - System degraded but functional

4. Storage per shard:
   Total: 10 TB
   Per shard: 1 TB
   With indexes (2x): 2 TB per shard
```

### Quick Estimation Template
```
For any system, estimate:

1. QPS (Queries Per Second)
   - Daily active users Ã— actions per user / 86400
   - Peak = average Ã— 3

2. Storage
   - Objects count Ã— size per object
   - Ã— replication factor
   - Ã— retention period

3. Bandwidth
   - QPS Ã— average request size
   - QPS Ã— average response size

4. Servers needed
   - Total QPS / QPS per server
   - Ã— redundancy factor (2-3x)
```

---

## ğŸ—„ï¸ DATABASE DESIGN PATTERNS

### Relational vs NoSQL Decision Tree
```
Use Relational (PostgreSQL/MySQL) when:
âœ“ Need ACID transactions
âœ“ Complex queries with JOINs
âœ“ Data has clear relationships
âœ“ Schema is stable
âœ“ Example: User management, billing

Use NoSQL (DynamoDB/MongoDB) when:
âœ“ Need horizontal scaling
âœ“ Schema flexibility required
âœ“ Simple key-value or document queries
âœ“ High write throughput
âœ“ Example: Session storage, logs, events

Use Time-Series (InfluxDB/TimescaleDB) when:
âœ“ Time-stamped data (metrics, logs)
âœ“ Need time-based queries
âœ“ High write volume
âœ“ Downsampling/aggregation
âœ“ Example: Monitoring, analytics

Use Graph (Neo4j) when:
âœ“ Relationship-heavy data
âœ“ Need path finding
âœ“ Social connections
âœ“ Example: Org charts, dependencies
```

### Data Partitioning Strategies
```
Horizontal Partitioning (Sharding):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partition by Hash:             â”‚
â”‚ shard = hash(customer_id) % N  â”‚
â”‚                                â”‚
â”‚ Pros:                          â”‚
â”‚ - Even distribution            â”‚
â”‚ - Simple to implement          â”‚
â”‚                                â”‚
â”‚ Cons:                          â”‚
â”‚ - Hard to add/remove shards    â”‚
â”‚ - No range queries across keys â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partition by Range:            â”‚
â”‚ Shard 1: A-M                   â”‚
â”‚ Shard 2: N-Z                   â”‚
â”‚                                â”‚
â”‚ Pros:                          â”‚
â”‚ - Easy range queries           â”‚
â”‚ - Easy to add shards           â”‚
â”‚                                â”‚
â”‚ Cons:                          â”‚
â”‚ - Hot spots possible           â”‚
â”‚ - Uneven distribution          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partition by Geography:        â”‚
â”‚ US-East, US-West, EU, Asia     â”‚
â”‚                                â”‚
â”‚ Pros:                          â”‚
â”‚ - Low latency for users        â”‚
â”‚ - Data sovereignty compliance  â”‚
â”‚                                â”‚
â”‚ Cons:                          â”‚
â”‚ - Uneven load                  â”‚
â”‚ - Complex cross-region queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Caching Strategy
```
Cache-Aside (Lazy Loading):
1. App checks cache
2. If miss, query database
3. Write to cache
4. Return data

Pros: Only cache what's needed
Cons: First request is slow

Write-Through:
1. App writes to cache
2. Cache writes to database
3. Return success

Pros: Cache always consistent
Cons: Write latency, unused data cached

Write-Behind (Write-Back):
1. App writes to cache
2. Return success immediately
3. Cache writes to DB async

Pros: Fast writes
Cons: Risk of data loss

Refresh-Ahead:
1. Predict what will be needed
2. Pre-load into cache
3. Refresh before TTL expires

Pros: Low latency
Cons: Complex, may cache unused data
```

---

## ğŸ”„ CAP THEOREM & CONSISTENCY

### CAP Theorem
```
Can only guarantee 2 of 3:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ C - Consistency                 â”‚
â”‚ All nodes see same data         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ A - Availability                â”‚
â”‚ System responds to all requests â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ P - Partition Tolerance         â”‚
â”‚ System works despite network    â”‚
â”‚ partitions                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

In practice, network partitions WILL happen
So choose between CP or AP:

CP Systems (Consistency + Partition):
- MongoDB (with majority writes)
- HBase, Redis
- Better for: Banking, inventory
- Trade-off: May reject requests

AP Systems (Availability + Partition):
- Cassandra, DynamoDB
- Riak, CouchDB
- Better for: Social media, caching
- Trade-off: Eventual consistency
```

### Consistency Levels
```
Strong Consistency:
- Read always returns latest write
- Example: Bank account balance
- Implementation: Synchronous replication
- Latency: High

Eventual Consistency:
- Reads may return stale data temporarily
- Example: Social media likes count
- Implementation: Async replication
- Latency: Low

Causal Consistency:
- Related operations appear in order
- Example: Comment thread (reply after post)
- Implementation: Version vectors
- Latency: Medium

Read-Your-Writes:
- User sees their own updates immediately
- Example: Profile update
- Implementation: Sticky sessions + cache
- Latency: Medium
```

---

## ğŸ“ USING THESE DIAGRAMS IN YOUR INTERVIEW

### Time-Boxed Approach (45-min Interview)
```
Minutes 0-5: Requirements Clarification
- Functional requirements (what features?)
- Non-functional (scale, latency, consistency?)
- Write them down on the board

Minutes 5-10: Capacity Estimation
- Users, QPS, storage
- Show the math
- This impresses interviewers!

Minutes 10-25: High-Level Design
- Draw major components (boxes)
- Show data flow (arrows)
- Explain each component briefly
- Get interviewer buy-in

Minutes 25-40: Deep Dive
- Pick 2-3 components interviewer cares about
- Discuss: scaling, failures, monitoring
- Show database schema
- Explain algorithms

Minutes 40-45: Wrap Up & Questions
- Bottlenecks identified
- Trade-offs discussed
- What you'd do differently with more time
- Ask interviewer for feedback
```

### Drawing Tips
1. **Start simple** - Box for each major component
2. **Show data flow** - Arrows with direction
3. **Label everything** - Component names and responsibilities
4. **Add numbers** - Scale, latency, throughput
5. **Iterate** - Start high-level, then drill down
6. **Use the whiteboard strategically** - Leave space for details

### What to Mention (Critical Talking Points)
1. **Technology Choices**
   - "I chose Kafka over RabbitMQ because..."
   - "Redis works here due to..."
   - Always give pros/cons

2. **Trade-offs**
   - "We trade consistency for availability here"
   - "This adds latency but improves reliability"
   - Show you understand no perfect solution

3. **Scaling**
   - "This scales horizontally by adding pods"
   - "We shard by customer_id for isolation"
   - "Current design handles 10K QPS, can scale to 100K"

4. **Failure Scenarios**
   - "If cache goes down, we fall back to database"
   - "Circuit breaker prevents cascade failures"
   - "Replicas ensure no single point of failure"

5. **Monitoring**
   - "We track p95 latency, error rate, CPU"
   - "Alerts on SLA violations"
   - "Distributed tracing for debugging"

6. **Monday.com Context**
   - "This supports multi-tenancy with isolation"
   - "Handles 150K+ customers"
   - "Meets enterprise SLA requirements"

### Common Follow-ups & How to Answer

**Q: "How would you handle 10x traffic?"**
A: 
- Horizontal scaling (more pods/instances)
- Add caching layer (Redis)
- Database read replicas
- CDN for static content
- Async processing for non-critical paths
- Show the math: "Current 10K QPS, 10x = 100K QPS, need N servers"

**Q: "What if [component] fails?"**
A:
- Identify if it's a single point of failure
- Explain redundancy (replicas, backups)
- Graceful degradation strategy
- Monitoring and auto-recovery
- Example: "If Kafka fails, we buffer in-memory for 5 min, alert ops"

**Q: "How do you ensure data consistency?"**
A:
- Define consistency requirement (strong vs eventual)
- Explain consistency mechanism (2PC, Raft, etc.)
- Discuss trade-offs with availability
- Example: "User profile updates need read-your-writes, but likes can be eventual"

**Q: "How would you monitor this?"**
A:
- Golden Signals: Latency, Traffic, Errors, Saturation
- Metrics: Prometheus + Grafana
- Logs: ELK stack
- Traces: Jaeger/Zipkin
- Alerts: PagerDuty for critical issues
- Dashboards for each service

**Q: "What are the bottlenecks?"**
A:
- Identify resource constraints: CPU, memory, network, I/O
- Database is often the bottleneck (solution: caching, replicas, sharding)
- Single-threaded processing (solution: parallel workers)
- Network bandwidth (solution: compression, CDN)
- Show how you'd measure: profiling, load testing

**Q: "How do you handle hot spots?"**
A:
- Identify: Some customers/users much more active
- Solutions:
  - Consistent hashing with virtual nodes
  - Dedicated shards for large customers
  - Local caching
  - Rate limiting

**Q: "How do you deploy updates without downtime?"**
A:
- Blue-green deployment
- Rolling updates (Kubernetes)
- Feature flags
- Database migrations (backward compatible)
- Canary deployment (1% â†’ 10% â†’ 100%)

### Troubleshooting Scenarios (Expect These!)

**"Users report slow search results"**
1. Check metrics: Is latency high? (Grafana)
2. Check Elasticsearch cluster health
3. Check cache hit rate (Redis)
4. Look at slow query logs
5. Verify index optimization
6. Check if re-indexing is running
7. Solution: Scale ES cluster, optimize queries, increase cache

**"ML model predictions are incorrect"**
1. Check model drift metrics (PSI score)
2. Validate input features (schema changes?)
3. Compare training vs production data distribution
4. Check model version deployed
5. Review recent retraining logs
6. Solution: Retrain model, rollback to previous version, fix data pipeline

**"File uploads are failing"**
1. Check S3 bucket permissions
2. Check pre-signed URL expiration
3. Check file size limits
4. Review virus scan results
5. Check Lambda/worker health
6. Look at API Gateway logs
7. Solution: Fix permissions, increase timeout, scale workers

**"Database connection pool exhausted"**
1. Check active connections count
2. Look for long-running queries
3. Check for connection leaks in code
4. Review connection timeout settings
5. Check if one customer is using too many
6. Solution: Increase pool size, kill long queries, fix code, add rate limiting

**"Kafka consumer lag increasing"**
1. Check consumer health and throughput
2. Check if processing is slow
3. Check if partition count is sufficient
4. Look at error rates
5. Verify downstream services are healthy
6. Solution: Scale consumers, optimize processing, add partitions

---

## ğŸ¯ INTERVIEW DAY CHECKLIST

### Mental Preparation
- [ ] Review this document (30 min)
- [ ] Practice drawing 2-3 diagrams (20 min)
- [ ] Review capacity estimation formulas (10 min)
- [ ] Practice explaining out loud (10 min)

### During the Interview
1. **Listen carefully** to the question
2. **Ask clarifying questions** (5 min)
3. **State assumptions** out loud
4. **Think out loud** - Don't go silent
5. **Start simple** - Can always add complexity
6. **Check in** with interviewer - "Does this make sense?"
7. **Draw clearly** - Boxes, arrows, labels
8. **Use numbers** - Estimate scale
9. **Discuss trade-offs** - Show maturity
10. **End strong** - Summarize and ask questions

### Red Flags to Avoid
âŒ Jumping straight to solution without clarifying
âŒ Using buzzwords without understanding
âŒ Ignoring interviewer's hints/feedback
âŒ Over-engineering simple problems
âŒ Not considering failure scenarios
âŒ Forgetting about monitoring/observability
âŒ Not discussing trade-offs
âŒ Giving up when stuck

### Green Flags to Show
âœ… Ask insightful clarifying questions
âœ… Consider multiple approaches
âœ… Discuss pros/cons of each choice
âœ… Think about real-world constraints
âœ… Mention monitoring and debugging
âœ… Consider scalability from the start
âœ… Relate to Monday.com's context
âœ… Show enthusiasm and curiosity

---

**You've got comprehensive diagrams and strategies. Practice them out loud, stay calm, and show your thinking process. Good luck with your Monday.com interview!** ğŸš€ğŸ¯
